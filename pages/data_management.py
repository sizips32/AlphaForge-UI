"""
ë°ì´í„° ê´€ë¦¬ í˜ì´ì§€
ë°ì´í„° ì—…ë¡œë“œ, ê²€ì¦, ë¯¸ë¦¬ë³´ê¸°, ê¸°ì´ˆ í†µê³„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import io
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.config import DATA_VALIDATION, UI_SETTINGS
from utils.data_processor import DataProcessor
from utils.validators import DataValidator
from utils.yahoo_finance_downloader import YahooFinanceDownloader

def show_page():
    """ë°ì´í„° ê´€ë¦¬ í˜ì´ì§€ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    # ë©”ì¸ íƒ€ì´í‹€ê³¼ ì„¤ëª…
    col_title, col_status = st.columns([3, 1])
    
    with col_title:
        st.title("ğŸ“ˆ ë°ì´í„° ê´€ë¦¬")
        st.markdown("ì£¼ê°€ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  ê²€ì¦í•˜ì—¬ AlphaForge ë¶„ì„ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.")
    
    with col_status:
        # ë°ì´í„° ìƒíƒœ í‘œì‹œ
        if 'processed_data' in st.session_state:
            data = st.session_state['processed_data']
            st.success(f"âœ… ì²˜ë¦¬ëœ ë°ì´í„°")
            st.metric("ë°ì´í„° ìˆ˜", f"{len(data):,}")
        elif 'uploaded_data' in st.session_state:
            data = st.session_state['uploaded_data']
            st.warning(f"âš ï¸ ì—…ë¡œë“œëœ ë°ì´í„°")
            st.metric("ë°ì´í„° ìˆ˜", f"{len(data):,}")
        else:
            st.info("ğŸ“ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”")
    
    st.markdown("---")
    
    # ë©”ì¸ ì»¨í…ì¸  ì˜ì—­
    if 'processed_data' in st.session_state or 'uploaded_data' in st.session_state:
        # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°: ë¯¸ë¦¬ë³´ê¸°ì™€ í†µê³„ ì¤‘ì‹¬ ë ˆì´ì•„ì›ƒ
        show_data_loaded_layout()
    else:
        # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°: ì—…ë¡œë“œ ì¤‘ì‹¬ ë ˆì´ì•„ì›ƒ
        show_upload_centered_layout()

def show_upload_centered_layout():
    """ë°ì´í„° ì—…ë¡œë“œ ì¤‘ì‹¬ ë ˆì´ì•„ì›ƒ"""
    # ì—…ë¡œë“œ ë°©ì‹ ì„ íƒ íƒ­
    upload_tab1, upload_tab2, upload_tab3 = st.tabs([
        "ğŸš€ ì•¼í›„ íŒŒì´ë‚¸ìŠ¤", 
        "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", 
        "ğŸ“‹ ìƒ˜í”Œ ë°ì´í„°"
    ])
    
    with upload_tab1:
        show_yahoo_finance_download()
    
    with upload_tab2:
        show_file_upload()
    
    with upload_tab3:
        show_sample_data_download()

def show_data_loaded_layout():
    """ë°ì´í„°ê°€ ë¡œë“œëœ ê²½ìš°ì˜ ë ˆì´ì•„ì›ƒ"""
    # processed_dataê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ uploaded_data ì‚¬ìš©
    if 'processed_data' in st.session_state:
        data = st.session_state['processed_data']
    else:
        data = st.session_state['uploaded_data']
    
    # ìƒë‹¨ í†µê³„ ì¹´ë“œ
    show_quick_stats(data)
    
    # ë©”ì¸ ì»¨í…ì¸  íƒ­
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°", "ğŸ“ˆ í†µê³„ ë¶„ì„", "ğŸ”§ ë°ì´í„° ê´€ë¦¬"])
    
    with tab1:
        show_data_preview()
    
    with tab2:
        show_detailed_analysis(data)
    
    with tab3:
        show_data_management_tools(data)

def show_quick_stats(data):
    """ìƒë‹¨ ë¹ ë¥¸ í†µê³„ ì¹´ë“œ"""
    stats = calculate_basic_stats(data)
    
    # 4-ì»¬ëŸ¼ í†µê³„ ì¹´ë“œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ì´ ë°ì´í„° ìˆ˜", 
            f"{stats['total_rows']:,}",
            help="ì—…ë¡œë“œëœ ì´ ë°ì´í„° í–‰ ìˆ˜"
        )
    
    with col2:
        st.metric(
            "ì¢…ëª© ìˆ˜", 
            f"{stats['unique_tickers']:,}",
            help="ê³ ìœ í•œ ì¢…ëª© ìˆ˜"
        )
    
    with col3:
        quality_score = calculate_quality_score(data)
        st.metric(
            "ë°ì´í„° í’ˆì§ˆ", 
            f"{quality_score:.1f}%",
            help="ë°ì´í„° í’ˆì§ˆ ì ìˆ˜"
        )
    
    with col4:
        st.metric(
            "ê¸°ê°„", 
            stats['date_range'],
            help="ë°ì´í„°ì˜ ë‚ ì§œ ë²”ìœ„"
        )

def show_yahoo_finance_download():
    """ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì„¹ì…˜"""
    st.markdown("### ğŸ“Š ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
    
    # Yahoo Finance ë‹¤ìš´ë¡œë” ì´ˆê¸°í™”
    if 'yahoo_downloader' not in st.session_state:
        st.session_state['yahoo_downloader'] = YahooFinanceDownloader()
    
    downloader = st.session_state['yahoo_downloader']
    
    # 2-ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ (ë” ê· í˜•ì¡íŒ ë¹„ìœ¨)
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("#### ğŸ¯ í‹°ì»¤ ì„ íƒ")
        
        # í‹°ì»¤ ì…ë ¥ ë°©ì‹ ì„ íƒ
        ticker_input_method = st.radio(
            "í‹°ì»¤ ì…ë ¥ ë°©ì‹",
            ["ì¸ê¸° ì¢…ëª© ì„ íƒ", "ì‹œì¥ ì§€ìˆ˜ ì„ íƒ", "ì§ì ‘ ì…ë ¥"],
            help="ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í‹°ì»¤ë¥¼ ì„ íƒí•˜ì„¸ìš”"
        )
        
        selected_tickers = []
        
        if ticker_input_method == "ì¸ê¸° ì¢…ëª© ì„ íƒ":
            popular_tickers = downloader.get_popular_tickers()
            
            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
            categories = {}
            for ticker in popular_tickers:
                cat = ticker['category']
                if cat not in categories:
                    categories[cat] = []
                categories[cat].append(ticker)
            
            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì„ íƒ (ë” ì»´íŒ©íŠ¸í•˜ê²Œ)
            for category, tickers in categories.items():
                with st.expander(f"ğŸ“‚ {category}", expanded=False):
                    # ì²´í¬ë°•ìŠ¤ë¥¼ 2ì—´ë¡œ ë°°ì¹˜
                    cols = st.columns(2)
                    for i, ticker in enumerate(tickers):
                        col_idx = i % 2
                        with cols[col_idx]:
                            if st.checkbox(f"{ticker['symbol']}", key=f"pop_{ticker['symbol']}"):
                                selected_tickers.append(ticker['symbol'])
                                st.caption(ticker['name'])
        
        elif ticker_input_method == "ì‹œì¥ ì§€ìˆ˜ ì„ íƒ":
            indices = downloader.get_market_indices()
            
            for index in indices:
                if st.checkbox(f"{index['symbol']} - {index['name']}", key=f"idx_{index['symbol']}"):
                    selected_tickers.append(index['symbol'])
        
        else:  # ì§ì ‘ ì…ë ¥
            ticker_input = st.text_area(
                "í‹°ì»¤ ì‹¬ë³¼ ì…ë ¥",
                placeholder="AAPL\nGOOGL\nMSFT\nTSLA",
                help="í•œ ì¤„ì— í•˜ë‚˜ì”© í‹°ì»¤ ì‹¬ë³¼ì„ ì…ë ¥í•˜ì„¸ìš”",
                height=100
            )
            
            if ticker_input:
                input_tickers = [t.strip().upper() for t in ticker_input.split('\n') if t.strip()]
                selected_tickers.extend(input_tickers)
        
        # ì„ íƒëœ í‹°ì»¤ í‘œì‹œ
        if selected_tickers:
            st.success(f"âœ… ì„ íƒëœ í‹°ì»¤: {len(selected_tickers)}ê°œ")
            # ì„ íƒëœ í‹°ì»¤ë¥¼ íƒœê·¸ í˜•íƒœë¡œ í‘œì‹œ
            ticker_tags = " ".join([f"`{ticker}`" for ticker in selected_tickers[:10]])
            st.markdown(ticker_tags)
            if len(selected_tickers) > 10:
                st.caption(f"... ë° {len(selected_tickers) - 10}ê°œ ë”")
    
    with col2:
        st.markdown("#### ğŸ“… ë‚ ì§œ ë²”ìœ„ ì„¤ì •")
        
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        date_range_option = st.selectbox(
            "ë‚ ì§œ ë²”ìœ„",
            ["ìµœê·¼ 1ë…„", "ìµœê·¼ 2ë…„", "ìµœê·¼ 5ë…„", "ìµœê·¼ 10ë…„", "ì§ì ‘ ì„¤ì •"],
            help="ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        if date_range_option == "ì§ì ‘ ì„¤ì •":
            col_date1, col_date2 = st.columns(2)
            with col_date1:
                start_date = st.date_input("ì‹œì‘ ë‚ ì§œ", value=datetime.now() - timedelta(days=365))
            with col_date2:
                end_date = st.date_input("ì¢…ë£Œ ë‚ ì§œ", value=datetime.now())
        else:
            # ë¯¸ë¦¬ ì •ì˜ëœ ê¸°ê°„
            end_date = datetime.now()
            if date_range_option == "ìµœê·¼ 1ë…„":
                start_date = end_date - timedelta(days=365)
            elif date_range_option == "ìµœê·¼ 2ë…„":
                start_date = end_date - timedelta(days=730)
            elif date_range_option == "ìµœê·¼ 5ë…„":
                start_date = end_date - timedelta(days=1825)
            else:  # ìµœê·¼ 10ë…„
                start_date = end_date - timedelta(days=3650)
        
        # ë‚ ì§œ í˜•ì‹ ë³€í™˜
        start_date_str = start_date.strftime('%Y-%m-%d')
        end_date_str = end_date.strftime('%Y-%m-%d')
        
        # ë‚ ì§œ ì •ë³´ë¥¼ ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
        st.info(f"""
        ğŸ“… **ë°ì´í„° ê¸°ê°„**
        - ì‹œì‘: {start_date_str}
        - ì¢…ë£Œ: {end_date_str}
        - ì´ ì¼ìˆ˜: {(end_date - start_date).days}ì¼
        """)
        
        # ë‚ ì§œ ìœ íš¨ì„± ê²€ì¦
        is_valid_date, date_error = downloader.validate_date_range(start_date_str, end_date_str)
        if not is_valid_date:
            st.error(f"âŒ ë‚ ì§œ ì˜¤ë¥˜: {date_error}")
            return
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ë” ëˆˆì— ë„ê²Œ)
    st.markdown("---")
    
    download_col1, download_col2, download_col3 = st.columns([1, 2, 1])
    
    with download_col2:
        if st.button("ğŸš€ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘", type="primary", use_container_width=True):
            if not selected_tickers:
                st.error("âŒ ìµœì†Œ í•˜ë‚˜ì˜ í‹°ì»¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                return
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # í‹°ì»¤ ìœ íš¨ì„± ê²€ì¦
            status_text.text("í‹°ì»¤ ìœ íš¨ì„± ê²€ì¦ ì¤‘...")
            progress_bar.progress(20)
            
            valid_tickers = []
            invalid_tickers = []
            
            for ticker in selected_tickers:
                if downloader.validate_ticker(ticker):
                    valid_tickers.append(ticker)
                else:
                    invalid_tickers.append(ticker)
            
            if invalid_tickers:
                st.warning(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ í‹°ì»¤: {', '.join(invalid_tickers)}")
            
            if not valid_tickers:
                st.error("âŒ ìœ íš¨í•œ í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤í–‰
            status_text.text("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...")
            progress_bar.progress(50)
            
            try:
                data, failed_tickers = downloader.download_multiple_tickers(
                    valid_tickers, start_date_str, end_date_str
                )
                
                progress_bar.progress(80)
                status_text.text("ë°ì´í„° ê²€ì¦ ì¤‘...")
                
                if not data.empty:
                    # ì„¸ì…˜ ìƒíƒœì— ë°ì´í„° ì €ì¥
                    st.session_state['uploaded_data'] = data
                    st.session_state['data_filename'] = f"yahoo_finance_{start_date_str}_{end_date_str}"
                    
                    # ë°ì´í„° ìë™ ì²˜ë¦¬
                    status_text.text("ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
                    progress_bar.progress(85)
                    
                    try:
                        from utils.data_processor import DataProcessor
                        processor = DataProcessor()
                        processed_data = processor.process_data(data)
                        st.session_state['processed_data'] = processed_data
                        st.session_state['data_processor'] = processor
                    except Exception as e:
                        st.warning(f"âš ï¸ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        # ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë°ì´í„°ë¼ë„ ì—…ë¡œë“œëœ ë°ì´í„°ëŠ” ì‚¬ìš© ê°€ëŠ¥
                    
                    # ë°ì´í„° ìš”ì•½ í‘œì‹œ
                    summary = downloader.get_data_summary(data)
                    
                    progress_bar.progress(100)
                    status_text.text("ì™„ë£Œ!")
                    
                    # ì„±ê³µ ë©”ì‹œì§€ë¥¼ ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
                    st.success("âœ… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬ ì™„ë£Œ!")
                    
                    # ìš”ì•½ ì •ë³´ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ í‘œì‹œ
                    summary_col1, summary_col2, summary_col3 = st.columns(3)
                    
                    with summary_col1:
                        st.metric("ì´ ë°ì´í„°", f"{summary['total_rows']:,}")
                    
                    with summary_col2:
                        st.metric("ì¢…ëª© ìˆ˜", f"{summary['unique_tickers']}")
                    
                    with summary_col3:
                        st.metric("ë°ì´í„° ì™„ì„±ë„", f"{summary['data_completeness']:.1f}%")
                    
                    if failed_tickers:
                        st.warning(f"âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {', '.join(failed_tickers)}")
                    
                    # ë°ì´í„° ê²€ì¦
                    validation_result = validate_data(data)
                    if validation_result['is_valid']:
                        st.success("âœ… ë°ì´í„° ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.warning("âš ï¸ ë°ì´í„° ê²€ì¦ì—ì„œ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        for issue in validation_result['issues']:
                            st.error(f"â€¢ {issue}")
                
                else:
                    st.error("âŒ ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                st.error(f"âŒ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def show_file_upload():
    """íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜"""
    st.markdown("### ğŸ“ íŒŒì¼ì—ì„œ ë°ì´í„° ì—…ë¡œë“œ")
    
    # ë“œë˜ê·¸ ì•¤ ë“œë¡­ ìŠ¤íƒ€ì¼ì˜ ì—…ë¡œë”
    uploaded_file = st.file_uploader(
        "ì£¼ê°€ ë°ì´í„° íŒŒì¼ì„ ì„ íƒí•˜ê±°ë‚˜ ë“œë˜ê·¸í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['csv', 'xlsx', 'xls', 'parquet'],
        help="CSV, Excel, Parquet í˜•ì‹ ì§€ì›"
    )
    
    if uploaded_file is not None:
        # íŒŒì¼ ì •ë³´ë¥¼ ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
        file_info = {
            "íŒŒì¼ëª…": uploaded_file.name,
            "í¬ê¸°": f"{uploaded_file.size / 1024:.1f} KB",
            "íƒ€ì…": uploaded_file.type
        }
        
        st.info(f"""
        ğŸ“„ **ì—…ë¡œë“œëœ íŒŒì¼**
        - íŒŒì¼ëª…: {file_info['íŒŒì¼ëª…']}
        - í¬ê¸°: {file_info['í¬ê¸°']}
        - íƒ€ì…: {file_info['íƒ€ì…']}
        """)
        
        # ë°ì´í„° ë¡œë“œ
        try:
            with st.spinner("ë°ì´í„° ë¡œë“œ ì¤‘..."):
                data = load_data(uploaded_file)
                
            if data is not None and not data.empty:
                # ë°ì´í„° ê²€ì¦
                validation_result = validate_data(data)
                
                if validation_result['is_valid']:
                    # ì„¸ì…˜ ìƒíƒœì— ë°ì´í„° ì €ì¥
                    st.session_state['uploaded_data'] = data
                    st.session_state['data_filename'] = uploaded_file.name
                    
                    # ë°ì´í„° ìë™ ì²˜ë¦¬
                    with st.spinner("ë°ì´í„° ì²˜ë¦¬ ì¤‘..."):
                        try:
                            from utils.data_processor import DataProcessor
                            processor = DataProcessor()
                            processed_data = processor.process_data(data)
                            st.session_state['processed_data'] = processed_data
                            st.session_state['data_processor'] = processor
                            st.success("âœ… ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ê³  ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        except Exception as e:
                            st.warning(f"âš ï¸ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                            st.info("ì—…ë¡œë“œëœ ì›ë³¸ ë°ì´í„°ëŠ” ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                            # ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë°ì´í„°ë¼ë„ ì—…ë¡œë“œëœ ë°ì´í„°ëŠ” ì‚¬ìš© ê°€ëŠ¥
                    
                    # ë°ì´í„° ìš”ì•½ ì •ë³´ í‘œì‹œ
                    st.success("âœ… ë°ì´í„° ê²€ì¦ì„ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì´ í–‰ ìˆ˜", f"{len(data):,}")
                    with col2:
                        if 'Ticker' in data.columns:
                            st.metric("ì¢…ëª© ìˆ˜", f"{data['Ticker'].nunique()}")
                        else:
                            st.metric("ì¢…ëª© ìˆ˜", "N/A")
                    with col3:
                        if 'Date' in data.columns:
                            date_range = f"{data['Date'].min()} ~ {data['Date'].max()}"
                            st.metric("ê¸°ê°„", date_range[:20] + "..." if len(date_range) > 20 else date_range)
                        else:
                            st.metric("ê¸°ê°„", "N/A")
                else:
                    st.error("âŒ ë°ì´í„° ê²€ì¦ì„ í†µê³¼í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    for issue in validation_result['issues']:
                        st.error(f"â€¢ {issue}")
                    
                    # ë¶€ë¶„ì ìœ¼ë¡œë¼ë„ ë°ì´í„° ì €ì¥ ì‹œë„
                    if len(data) > 0:
                        st.warning("âš ï¸ ê²€ì¦ì— ì‹¤íŒ¨í–ˆì§€ë§Œ ë°ì´í„°ëŠ” ì €ì¥ë©ë‹ˆë‹¤.")
                        st.session_state['uploaded_data'] = data
                        st.session_state['data_filename'] = uploaded_file.name
            else:
                st.error("âŒ ë°ì´í„°ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
            st.error("íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

def show_sample_data_download():
    """ìƒ˜í”Œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì„¹ì…˜"""
    st.markdown("### ğŸ“‹ ìƒ˜í”Œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
    st.markdown("AlphaForge ë¶„ì„ì„ ìœ„í•œ ìƒ˜í”Œ ì£¼ê°€ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
    
    # ìƒ˜í”Œ ë°ì´í„° ì •ë³´
    st.info("""
    ğŸ“Š **ìƒ˜í”Œ ë°ì´í„° í¬í•¨ ë‚´ìš©**
    - 10ê°œ ì£¼ìš” ì¢…ëª© (AAPL, GOOGL, MSFT ë“±)
    - ìµœê·¼ 2ë…„ê°„ì˜ ì¼ë³„ ë°ì´í„°
    - OHLCV (ì‹œê°€, ê³ ê°€, ì €ê°€, ì¢…ê°€, ê±°ë˜ëŸ‰) ë°ì´í„°
    - CSV í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
    """)
    
    if st.button("ğŸ“¥ ìƒ˜í”Œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", use_container_width=True):
        with st.spinner("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘..."):
            try:
                sample_data = create_sample_data()
                
                if sample_data is not None and not sample_data.empty:
                    # ì„¸ì…˜ ìƒíƒœì— ë°ì´í„° ì €ì¥ ë° ì²˜ë¦¬
                    st.session_state['uploaded_data'] = sample_data
                    st.session_state['data_filename'] = "sample_stock_data.csv"
                    
                    # ë°ì´í„° ìë™ ì²˜ë¦¬
                    try:
                        from utils.data_processor import DataProcessor
                        processor = DataProcessor()
                        processed_data = processor.process_data(sample_data)
                        st.session_state['processed_data'] = processed_data
                        st.session_state['data_processor'] = processor
                        st.success("âœ… ìƒ˜í”Œ ë°ì´í„°ê°€ ìƒì„±ë˜ê³  ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    except Exception as e:
                        st.warning(f"âš ï¸ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        st.info("ì—…ë¡œë“œëœ ì›ë³¸ ë°ì´í„°ëŠ” ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")
                    
                    # ë°ì´í„° ìš”ì•½ ì •ë³´ í‘œì‹œ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì´ í–‰ ìˆ˜", f"{len(sample_data):,}")
                    with col2:
                        if 'Ticker' in sample_data.columns:
                            st.metric("ì¢…ëª© ìˆ˜", f"{sample_data['Ticker'].nunique()}")
                        else:
                            st.metric("ì¢…ëª© ìˆ˜", "N/A")
                    with col3:
                        if 'Date' in sample_data.columns:
                            date_range = f"{sample_data['Date'].min()} ~ {sample_data['Date'].max()}"
                            st.metric("ê¸°ê°„", date_range[:20] + "..." if len(date_range) > 20 else date_range)
                        else:
                            st.metric("ê¸°ê°„", "N/A")
                    
                    # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    csv = sample_data.to_csv(index=False)
                    st.download_button(
                        label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                        data=csv,
                        file_name="sample_stock_data.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
                else:
                    st.error("âŒ ìƒ˜í”Œ ë°ì´í„° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def show_data_preview():
    """ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ì„¹ì…˜"""
    # processed_dataê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ uploaded_data ì‚¬ìš©
    if 'processed_data' in st.session_state:
        data = st.session_state['processed_data']
        data_type = "ì²˜ë¦¬ëœ ë°ì´í„°"
    elif 'uploaded_data' in st.session_state:
        data = st.session_state['uploaded_data']
        data_type = "ì—…ë¡œë“œëœ ë°ì´í„°"
    else:
        st.info("ğŸ“ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë¯¸ë¦¬ë³´ê¸°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # ë°ì´í„° ì •ë³´ í—¤ë”
    col_info1, col_info2, col_info3 = st.columns(3)
    
    with col_info1:
        st.metric("ì´ í–‰ ìˆ˜", f"{len(data):,}")
    
    with col_info2:
        st.metric("ì´ ì»¬ëŸ¼ ìˆ˜", f"{len(data.columns)}")
    
    with col_info3:
        missing_data = data.isnull().sum().sum()
        st.metric("ê²°ì¸¡ì¹˜ ìˆ˜", f"{missing_data:,}")
    
    # ë°ì´í„° íƒ€ì… í‘œì‹œ
    st.info(f"ğŸ“Š í˜„ì¬ í‘œì‹œ ì¤‘: {data_type}")
    
    # ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ ë°ì´í„°ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´ í‘œì‹œ
    if 'yahoo_downloader' in st.session_state and 'data_filename' in st.session_state:
        if st.session_state['data_filename'].startswith('yahoo_finance'):
            show_yahoo_data_info(data)
    
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° ì„¤ì •
    preview_col1, preview_col2 = st.columns([3, 1])
    
    with preview_col1:
        preview_rows = st.slider("ë¯¸ë¦¬ë³´ê¸° í–‰ ìˆ˜", 5, 100, 20)
    
    with preview_col2:
        if st.button("ì „ì²´ ë°ì´í„° ë³´ê¸°", use_container_width=True):
            preview_rows = len(data)
    
    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    st.dataframe(data.head(preview_rows), use_container_width=True)
    
    # ì»¬ëŸ¼ ì •ë³´
    with st.expander("ğŸ“‹ ì»¬ëŸ¼ ì •ë³´", expanded=False):
        col_info = pd.DataFrame({
            'ì»¬ëŸ¼ëª…': data.columns,
            'ë°ì´í„° íƒ€ì…': data.dtypes.astype(str),
            'ê²°ì¸¡ì¹˜ ìˆ˜': data.isnull().sum(),
            'ê²°ì¸¡ì¹˜ ë¹„ìœ¨': (data.isnull().sum() / len(data) * 100).round(2)
        })
        st.dataframe(col_info, use_container_width=True)
    
    # ë°ì´í„° ì‹œê°í™”
    with st.expander("ğŸ“ˆ ë°ì´í„° ì‹œê°í™”", expanded=False):
        show_data_visualization(data)

def show_detailed_analysis(data):
    """ìƒì„¸ í†µê³„ ë¶„ì„ ì„¹ì…˜"""
    st.markdown("### ğŸ“ˆ ìƒì„¸ í†µê³„ ë¶„ì„")
    
    # ë¶„ì„ íƒ­
    analysis_tab1, analysis_tab2, analysis_tab3 = st.tabs(["ğŸ“Š ê¸°ë³¸ í†µê³„", "ğŸ“ˆ ì‹œê³„ì—´ ë¶„ì„", "ğŸ” ë°ì´í„° í’ˆì§ˆ"])
    
    with analysis_tab1:
        show_basic_stats()
    
    with analysis_tab2:
        show_time_series_analysis(data)
    
    with analysis_tab3:
        show_data_quality_analysis(data)

def show_data_management_tools(data):
    """ë°ì´í„° ê´€ë¦¬ ë„êµ¬ ì„¹ì…˜"""
    st.markdown("### ğŸ”§ ë°ì´í„° ê´€ë¦¬ ë„êµ¬")
    
    # ê´€ë¦¬ ë„êµ¬ íƒ­
    tools_tab1, tools_tab2, tools_tab3 = st.tabs(["ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨", "ğŸ’¾ ë°ì´í„° ì €ì¥", "ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ"])
    
    with tools_tab1:
        st.markdown("#### ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨")
        st.info("ìµœì‹  ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸í•˜ë ¤ë©´ ìœ„ì˜ ì—…ë¡œë“œ ì„¹ì…˜ì„ ë‹¤ì‹œ ì‚¬ìš©í•˜ì„¸ìš”.")
    
    with tools_tab2:
        st.markdown("#### ğŸ’¾ ë°ì´í„° ì €ì¥")
        if st.button("CSVë¡œ ì €ì¥", use_container_width=True):
            csv = data.to_csv(index=False)
            st.download_button(
                label="ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"stock_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
                use_container_width=True
            )
    
    with tools_tab3:
        st.markdown("#### ğŸ—‘ï¸ ë°ì´í„° ì‚­ì œ")
        if st.button("ë°ì´í„° ì‚­ì œ", type="secondary", use_container_width=True):
            # ë°ì´í„° ê´€ë ¨ ì„¸ì…˜ ì‚­ì œ
            if 'uploaded_data' in st.session_state:
                del st.session_state['uploaded_data']
            if 'processed_data' in st.session_state:
                del st.session_state['processed_data']
            if 'data_processor' in st.session_state:
                del st.session_state['data_processor']
            if 'data_filename' in st.session_state:
                del st.session_state['data_filename']
            
            # íŒ©í„° ë§ˆì´ë‹ ê²°ê³¼ ì‚­ì œ (ë°ì´í„°ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ)
            if 'mining_results' in st.session_state:
                del st.session_state['mining_results']
            
            # ë™ì  ê²°í•© ê²°ê³¼ ì‚­ì œ (íŒ©í„°ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë¯€ë¡œ)
            if 'combination_results' in st.session_state:
                del st.session_state['combination_results']
            
            # ê¸°ë³¸ íŒ©í„° ì‚¬ìš© ì„¤ì • ì‚­ì œ
            if 'use_default_factors' in st.session_state:
                del st.session_state['use_default_factors']
            
            st.success("ë°ì´í„°ì™€ ê´€ë ¨ ê²°ê³¼ê°€ ëª¨ë‘ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()

def show_time_series_analysis(data):
    """ì‹œê³„ì—´ ë¶„ì„"""
    if 'Close' in data.columns and 'Date' in data.columns:
        try:
            # ì¢…ê°€ ì¶”ì´
            fig = px.line(
                data.groupby('Date')['Close'].mean().reset_index(),
                x='Date',
                y='Close',
                title="í‰ê·  ì¢…ê°€ ì¶”ì´"
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True, key="close_trend_chart")
            
            # ê±°ë˜ëŸ‰ ë¶„ì„
            if 'Volume' in data.columns:
                col_vol1, col_vol2 = st.columns(2)
                
                with col_vol1:
                    fig_vol = px.histogram(
                        data,
                        x='Volume',
                        title="ê±°ë˜ëŸ‰ ë¶„í¬",
                        nbins=50
                    )
                    fig_vol.update_layout(height=300)
                    st.plotly_chart(fig_vol, use_container_width=True, key="volume_distribution_chart")
                
                with col_vol2:
                    # ì›”ë³„ í‰ê·  ê±°ë˜ëŸ‰
                    data_copy = data.copy()
                    data_copy['Date'] = pd.to_datetime(data_copy['Date'])
                    data_copy['Month'] = data_copy['Date'].dt.to_period('M')
                    monthly_volume = data_copy.groupby('Month')['Volume'].mean().reset_index()
                    monthly_volume['Month'] = monthly_volume['Month'].astype(str)
                    
                    fig_monthly = px.bar(
                        monthly_volume,
                        x='Month',
                        y='Volume',
                        title="ì›”ë³„ í‰ê·  ê±°ë˜ëŸ‰"
                    )
                    fig_monthly.update_layout(height=300)
                    st.plotly_chart(fig_monthly, use_container_width=True, key="monthly_volume_chart")
        
        except Exception as e:
            st.error(f"ì‹œê³„ì—´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    else:
        st.warning("ì‹œê³„ì—´ ë¶„ì„ì„ ìœ„í•´ 'Date'ì™€ 'Close' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

def show_data_quality_analysis(data):
    """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
    st.markdown("#### ğŸ” ë°ì´í„° í’ˆì§ˆ ë¶„ì„")
    
    # í’ˆì§ˆ ì§€í‘œ ê³„ì‚°
    quality_score = calculate_quality_score(data)
    
    # í’ˆì§ˆ ì ìˆ˜ ê²Œì´ì§€
    st.metric("ì „ì²´ í’ˆì§ˆ ì ìˆ˜", f"{quality_score:.1f}%")
    
    # ìƒì„¸ í’ˆì§ˆ ì§€í‘œ
    col_qual1, col_qual2, col_qual3 = st.columns(3)
    
    with col_qual1:
        completeness = (1 - data.isnull().sum().sum() / (len(data) * len(data.columns))) * 100
        st.metric("ì™„ì „ì„±", f"{completeness:.1f}%")
    
    with col_qual2:
        # ì¼ê´€ì„± ì²´í¬ (ì˜ˆì‹œ)
        consistency = 95.0
        st.metric("ì¼ê´€ì„±", f"{consistency:.1f}%")
    
    with col_qual3:
        # ì •í™•ì„± ì²´í¬ (ì˜ˆì‹œ)
        accuracy = 98.0
        st.metric("ì •í™•ì„±", f"{accuracy:.1f}%")
    
    # ê²°ì¸¡ì¹˜ ë¶„ì„
    st.markdown("#### ğŸ“Š ê²°ì¸¡ì¹˜ ë¶„ì„")
    missing_data = data.isnull().sum()
    missing_data = missing_data[missing_data > 0]
    
    if len(missing_data) > 0:
        fig_missing = px.bar(
            x=missing_data.index,
            y=missing_data.values,
            title="ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ìˆ˜"
        )
        fig_missing.update_layout(height=300)
        st.plotly_chart(fig_missing, use_container_width=True, key="missing_data_chart")
    else:
        st.success("âœ… ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤!")

def show_yahoo_data_info(data):
    """ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ ë°ì´í„°ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.markdown("---")
    st.markdown("### ğŸ“Š ì•¼í›„ íŒŒì´ë‚¸ìŠ¤ ë°ì´í„° ì •ë³´")
    
    if 'Ticker' in data.columns:
        # ì¢…ëª©ë³„ í†µê³„
        ticker_stats = data.groupby('Ticker').agg({
            'Close': ['count', 'mean', 'std', 'min', 'max'],
            'Volume': ['mean', 'sum']
        }).round(2)
        
        ticker_stats.columns = ['ë°ì´í„° ìˆ˜', 'í‰ê·  ì¢…ê°€', 'í‘œì¤€í¸ì°¨', 'ìµœì €ê°€', 'ìµœê³ ê°€', 'í‰ê·  ê±°ë˜ëŸ‰', 'ì´ ê±°ë˜ëŸ‰']
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### ğŸ“ˆ ì¢…ëª©ë³„ ê¸°ë³¸ í†µê³„")
            st.dataframe(ticker_stats, use_container_width=True)
        
        with col2:
            st.markdown("#### ğŸ“Š ì¢…ëª©ë³„ ë°ì´í„° ë¶„í¬")
            
            # ì¢…ëª©ë³„ ë°ì´í„° ìˆ˜ ì°¨íŠ¸
            ticker_counts = data['Ticker'].value_counts()
            fig = px.bar(
                x=ticker_counts.index,
                y=ticker_counts.values,
                title="ì¢…ëª©ë³„ ë°ì´í„° ìˆ˜",
                labels={'x': 'í‹°ì»¤', 'y': 'ë°ì´í„° ìˆ˜'}
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True, key="yahoo_ticker_counts_chart")
        
        # ìµœê·¼ ë°ì´í„° í™•ì¸
        st.markdown("#### ğŸ“… ìµœê·¼ ë°ì´í„° í™•ì¸")
        recent_data = data.groupby('Ticker').tail(1).sort_values('Date', ascending=False)
        st.dataframe(recent_data[['Date', 'Ticker', 'Close', 'Volume']], use_container_width=True)

def show_basic_stats():
    """ê¸°ë³¸ í†µê³„ ì„¹ì…˜"""
    # processed_dataê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ uploaded_data ì‚¬ìš©
    if 'processed_data' in st.session_state:
        data = st.session_state['processed_data']
    elif 'uploaded_data' in st.session_state:
        data = st.session_state['uploaded_data']
    else:
        st.info("ğŸ“ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ì—¬ í†µê³„ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # ê¸°ë³¸ í†µê³„
    stats = calculate_basic_stats(data)
    
    # í†µê³„ ì¹´ë“œë“¤ì„ 2x2 ê·¸ë¦¬ë“œë¡œ ë°°ì¹˜
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("ì´ ë°ì´í„° ìˆ˜", f"{stats['total_rows']:,}")
        st.metric("ì¢…ëª© ìˆ˜", f"{stats['unique_tickers']:,}")
    
    with col2:
        st.metric("ê¸°ê°„", f"{stats['date_range']}")
        st.metric("í‰ê·  ì¢…ê°€", f"${stats['avg_close']:.2f}")
    
    # ì¢…ëª©ë³„ ìƒì„¸ í†µê³„
    if 'Ticker' in data.columns and 'Close' in data.columns:
        st.markdown("#### ğŸ“Š ì¢…ëª©ë³„ í†µê³„")
        
        ticker_stats = data.groupby('Ticker').agg({
            'Close': ['count', 'mean', 'std', 'min', 'max'],
            'Volume': ['mean', 'sum'] if 'Volume' in data.columns else ['count']
        }).round(2)
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        if 'Volume' in data.columns:
            ticker_stats.columns = ['ë°ì´í„° ìˆ˜', 'í‰ê·  ì¢…ê°€', 'í‘œì¤€í¸ì°¨', 'ìµœì €ê°€', 'ìµœê³ ê°€', 'í‰ê·  ê±°ë˜ëŸ‰', 'ì´ ê±°ë˜ëŸ‰']
        else:
            ticker_stats.columns = ['ë°ì´í„° ìˆ˜', 'í‰ê·  ì¢…ê°€', 'í‘œì¤€í¸ì°¨', 'ìµœì €ê°€', 'ìµœê³ ê°€']
        
        st.dataframe(ticker_stats, use_container_width=True)

def load_data(uploaded_file):
    """ì—…ë¡œë“œëœ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        file_extension = uploaded_file.name.split('.')[-1].lower()
        
        if file_extension == 'csv':
            data = pd.read_csv(uploaded_file)
        elif file_extension in ['xlsx', 'xls']:
            data = pd.read_excel(uploaded_file)
        elif file_extension == 'parquet':
            data = pd.read_parquet(uploaded_file)
        else:
            st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
            return None
        
        return data
    
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def validate_data(data):
    """ë°ì´í„° ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    try:
        validator = DataValidator()
        result = validator.validate(data)
        
        # ì¶”ê°€ ê²€ì¦ ë¡œì§
        if result['is_valid']:
            # ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = calculate_quality_score(data)
            result['quality_score'] = quality_score
            
            # ì¶”ê°€ ê¶Œì¥ì‚¬í•­
            recommendations = []
            
            # ë°ì´í„° í¬ê¸° í™•ì¸
            if len(data) < 1000:
                recommendations.append("ë°ì´í„°ê°€ ì ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
            # ì¢…ëª© ìˆ˜ í™•ì¸
            if 'Ticker' in data.columns and data['Ticker'].nunique() < 5:
                recommendations.append("ì¢…ëª© ìˆ˜ê°€ ì ìŠµë‹ˆë‹¤. ë” ë‹¤ì–‘í•œ ì¢…ëª©ì„ í¬í•¨í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
            # ë‚ ì§œ ë²”ìœ„ í™•ì¸
            if 'Date' in data.columns:
                date_range = (pd.to_datetime(data['Date'].max()) - pd.to_datetime(data['Date'].min())).days
                if date_range < 252:  # 1ë…„ ë¯¸ë§Œ
                    recommendations.append("ë°ì´í„° ê¸°ê°„ì´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 1ë…„ ì´ìƒì˜ ë°ì´í„°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")
            
            result['recommendations'] = recommendations
        
        return result
        
    except Exception as e:
        return {
            'is_valid': False,
            'issues': [f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"],
            'quality_score': 0,
            'recommendations': []
        }

def create_sample_data():
    """ìƒ˜í”Œ ì£¼ê°€ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    # ìƒ˜í”Œ ì¢…ëª©ë“¤
    tickers = ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'TSLA', 'META', 'NVDA', 'NFLX', 'ADBE', 'CRM']
    
    # ë‚ ì§œ ë²”ìœ„ (ìµœê·¼ 2ë…„)
    end_date = datetime.now()
    start_date = end_date - timedelta(days=730)
    dates = pd.date_range(start=start_date, end=end_date, freq='D')
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
    sample_data = []
    
    for ticker in tickers:
        # ê° ì¢…ëª©ë³„ë¡œ ë‹¤ë¥¸ ê¸°ë³¸ ê°€ê²© ì„¤ì •
        base_price = np.random.uniform(50, 500)
        
        for date in dates:
            # ì£¼ë§ ì œì™¸
            if date.weekday() < 5:
                # ë” í˜„ì‹¤ì ì¸ ê°€ê²© ë³€ë™ ìƒì„±
                price_change = np.random.normal(0, 0.02)  # 2% í‘œì¤€í¸ì°¨
                close_price = base_price * (1 + price_change)
                close_price = max(close_price, 1.0)  # ìµœì†Œ $1
                
                # OHLC ìƒì„±
                open_price = close_price * (1 + np.random.normal(0, 0.01))
                high_price = max(open_price, close_price) * (1 + np.random.uniform(0, 0.03))
                low_price = min(open_price, close_price) * (1 - np.random.uniform(0, 0.03))
                
                # ê±°ë˜ëŸ‰ ìƒì„± (ê°€ê²© ë³€ë™ê³¼ ì—°ê´€)
                base_volume = np.random.randint(1000000, 10000000)
                volume = int(base_volume * (1 + abs(price_change) * 10))  # ë³€ë™ì„±ì´ í´ ë•Œ ê±°ë˜ëŸ‰ ì¦ê°€
                
                sample_data.append({
                    'Date': date.strftime('%Y-%m-%d'),
                    'Ticker': ticker,
                    'Open': round(open_price, 2),
                    'High': round(high_price, 2),
                    'Low': round(low_price, 2),
                    'Close': round(close_price, 2),
                    'Volume': volume
                })
                
                # ë‹¤ìŒ ë‚ ì„ ìœ„í•œ ê¸°ë³¸ ê°€ê²© ì—…ë°ì´íŠ¸
                base_price = close_price
    
    df = pd.DataFrame(sample_data)
    
    # ë°ì´í„° ê²€ì¦
    if df.empty:
        raise ValueError("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: ë¹ˆ ë°ì´í„°í”„ë ˆì„")
    
    # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
    required_columns = ['Date', 'Ticker', 'Close']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
    
    # ë°ì´í„° íƒ€ì… í™•ì¸
    try:
        df['Date'] = pd.to_datetime(df['Date'])
        df['Close'] = pd.to_numeric(df['Close'])
        df['Ticker'] = df['Ticker'].astype(str)
    except Exception as e:
        raise ValueError(f"ë°ì´í„° íƒ€ì… ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
    
    # ìŒìˆ˜ ê°€ê²© í™•ì¸
    if (df['Close'] <= 0).any():
        raise ValueError("ìŒìˆ˜ ë˜ëŠ” 0 ê°€ê²©ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    print(f"ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(df)} í–‰, {df['Ticker'].nunique()} ì¢…ëª©")
    return df

def calculate_basic_stats(data):
    """ê¸°ë³¸ í†µê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    stats = {}
    
    # ê¸°ë³¸ ì •ë³´
    stats['total_rows'] = len(data)
    stats['unique_tickers'] = data['Ticker'].nunique() if 'Ticker' in data.columns else 0
    
    # ë‚ ì§œ ë²”ìœ„
    if 'Date' in data.columns:
        try:
            data['Date'] = pd.to_datetime(data['Date'])
            date_range = f"{data['Date'].min().strftime('%Y-%m-%d')} ~ {data['Date'].max().strftime('%Y-%m-%d')}"
            stats['date_range'] = date_range
        except:
            stats['date_range'] = "ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜"
    else:
        stats['date_range'] = "ë‚ ì§œ ì»¬ëŸ¼ ì—†ìŒ"
    
    # ì¢…ê°€ í†µê³„
    if 'Close' in data.columns:
        stats['avg_close'] = data['Close'].mean()
        stats['min_close'] = data['Close'].min()
        stats['max_close'] = data['Close'].max()
    else:
        stats['avg_close'] = 0
    
    # ë°ì´í„° í’ˆì§ˆ ì§€í‘œ
    stats['completeness'] = (1 - data.isnull().sum().sum() / (len(data) * len(data.columns))) * 100
    stats['consistency'] = 95.0  # ì˜ˆì‹œ ê°’
    stats['accuracy'] = 98.0     # ì˜ˆì‹œ ê°’
    
    return stats

def calculate_quality_score(data):
    """ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    # ì™„ì „ì„± (ê²°ì¸¡ì¹˜ ë¹„ìœ¨)
    completeness = (1 - data.isnull().sum().sum() / (len(data) * len(data.columns))) * 100
    
    # ì¼ê´€ì„± (ë°ì´í„° íƒ€ì… ì¼ì¹˜)
    consistency = 95.0  # ì˜ˆì‹œ ê°’
    
    # ì •í™•ì„± (ì´ìƒì¹˜ ë¹„ìœ¨)
    accuracy = 98.0  # ì˜ˆì‹œ ê°’
    
    # ì¢…í•© ì ìˆ˜
    quality_score = (completeness * 0.4 + consistency * 0.3 + accuracy * 0.3)
    
    return quality_score

def show_data_visualization(data):
    """ë°ì´í„° ì‹œê°í™”ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    if 'Close' in data.columns and 'Date' in data.columns:
        try:
            # ì¢…ê°€ ì‹œê³„ì—´ ì°¨íŠ¸
            fig = px.line(
                data.groupby('Date')['Close'].mean().reset_index(),
                x='Date',
                y='Close',
                title="í‰ê·  ì¢…ê°€ ì¶”ì´"
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True, key="preview_close_trend_chart")
            
            # ê±°ë˜ëŸ‰ ë¶„í¬
            if 'Volume' in data.columns:
                fig_vol = px.histogram(
                    data,
                    x='Volume',
                    title="ê±°ë˜ëŸ‰ ë¶„í¬",
                    nbins=50
                )
                fig_vol.update_layout(height=300)
                st.plotly_chart(fig_vol, use_container_width=True, key="preview_volume_distribution_chart")
        
        except Exception as e:
            st.error(f"ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")

if __name__ == "__main__":
    show_page() 
