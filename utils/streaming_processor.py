"""
ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ
ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ë° ì˜¨ë¼ì¸ í•™ìŠµ
"""

import time
import threading
import queue
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Callable, Generator, Iterator, Union
from dataclasses import dataclass, field
from enum import Enum
import numpy as np
import pandas as pd
from collections import deque, defaultdict
import asyncio
from pathlib import Path

from utils.logger import get_logger, log_performance
from utils.error_handler import handle_error, ErrorCategory, ErrorSeverity
from utils.realtime_updates import realtime_manager, UpdateType


class StreamingMode(Enum):
    """ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ"""
    CONTINUOUS = "continuous"
    MICRO_BATCH = "micro_batch"
    EVENT_DRIVEN = "event_driven"
    WINDOWED = "windowed"


class WindowType(Enum):
    """ìœˆë„ìš° íƒ€ì…"""
    TUMBLING = "tumbling"      # ê²¹ì¹˜ì§€ ì•ŠëŠ” ê³ ì • í¬ê¸° ìœˆë„ìš°
    SLIDING = "sliding"        # ê²¹ì¹˜ëŠ” ê³ ì • í¬ê¸° ìœˆë„ìš°
    SESSION = "session"        # í™œë™ ê¸°ë°˜ ê°€ë³€ í¬ê¸° ìœˆë„ìš°
    COUNT = "count"           # ê°œìˆ˜ ê¸°ë°˜ ìœˆë„ìš°


@dataclass
class StreamWindow:
    """ìŠ¤íŠ¸ë¦¼ ìœˆë„ìš°"""
    window_id: str
    window_type: WindowType
    size: Union[int, timedelta]
    slide: Optional[Union[int, timedelta]] = None
    data: deque = field(default_factory=deque)
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    is_complete: bool = False


@dataclass
class StreamingConfig:
    """ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •"""
    mode: StreamingMode
    buffer_size: int
    batch_size: int
    window_size: Union[int, timedelta]
    window_type: WindowType
    slide_interval: Optional[Union[int, timedelta]]
    max_latency_ms: int
    checkpoint_interval: int
    enable_backpressure: bool
    max_memory_mb: int


@dataclass
class StreamMetrics:
    """ìŠ¤íŠ¸ë¦¼ ë©”íŠ¸ë¦­"""
    processed_records: int = 0
    failed_records: int = 0
    avg_processing_time_ms: float = 0
    throughput_per_second: float = 0
    current_latency_ms: float = 0
    buffer_utilization: float = 0
    memory_usage_mb: float = 0
    last_update: datetime = field(default_factory=datetime.now)


class StreamingProcessor:
    """ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ì²˜ë¦¬ê¸°"""
    
    def __init__(self, config: StreamingConfig):
        """ì´ˆê¸°í™”"""
        self.config = config
        self.logger = get_logger("streaming_processor")
        
        # ìŠ¤íŠ¸ë¦¼ ìƒíƒœ
        self.is_running = False
        self.is_paused = False
        
        # ë°ì´í„° ë²„í¼
        self.input_buffer = queue.Queue(maxsize=config.buffer_size)
        self.output_buffer = queue.Queue()
        
        # ìœˆë„ìš° ê´€ë¦¬
        self.windows: Dict[str, StreamWindow] = {}
        self.window_counter = 0
        
        # ë©”íŠ¸ë¦­
        self.metrics = StreamMetrics()
        
        # ì²˜ë¦¬ í•¨ìˆ˜ë“¤
        self.processors: List[Callable] = []
        self.output_handlers: List[Callable] = []
        
        # ìŠ¤ë ˆë“œ ê´€ë¦¬
        self.processing_thread = None
        self.output_thread = None
        
        # ì²´í¬í¬ì¸íŠ¸
        self.last_checkpoint = datetime.now()
        
        # ë°±í”„ë ˆì…” ê´€ë¦¬
        self.backpressure_active = False
    
    def add_processor(self, processor: Callable):
        """ì²˜ë¦¬ í•¨ìˆ˜ ì¶”ê°€"""
        self.processors.append(processor)
        self.logger.info(f"Added processor: {processor.__name__}")
    
    def add_output_handler(self, handler: Callable):
        """ì¶œë ¥ í•¸ë“¤ëŸ¬ ì¶”ê°€"""
        self.output_handlers.append(handler)
        self.logger.info(f"Added output handler: {handler.__name__}")
    
    def start_stream(self):
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œì‘"""
        if self.is_running:
            self.logger.warning("Stream is already running")
            return
        
        self.is_running = True
        self.is_paused = False
        
        self.logger.info(f"Starting stream processing in {self.config.mode.value} mode")
        
        # ì²˜ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
        self.processing_thread = threading.Thread(
            target=self._processing_loop,
            name="StreamProcessor"
        )
        self.processing_thread.daemon = True
        self.processing_thread.start()
        
        # ì¶œë ¥ ìŠ¤ë ˆë“œ ì‹œì‘
        self.output_thread = threading.Thread(
            target=self._output_loop,
            name="StreamOutput"
        )
        self.output_thread.daemon = True
        self.output_thread.start()
        
        # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ìŠ¤ë ˆë“œ
        metrics_thread = threading.Thread(
            target=self._metrics_loop,
            name="StreamMetrics"
        )
        metrics_thread.daemon = True
        metrics_thread.start()
        
        self.logger.info("Stream processing started")
    
    def stop_stream(self):
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¤‘ì§€"""
        self.logger.info("Stopping stream processing")
        self.is_running = False
        
        # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if self.processing_thread:
            self.processing_thread.join(timeout=5)
        
        if self.output_thread:
            self.output_thread.join(timeout=5)
        
        # ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
        self._flush_remaining_data()
        
        self.logger.info("Stream processing stopped")
    
    def pause_stream(self):
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¼ì‹œ ì •ì§€"""
        self.is_paused = True
        self.logger.info("Stream processing paused")
    
    def resume_stream(self):
        """ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¬ê°œ"""
        self.is_paused = False
        self.logger.info("Stream processing resumed")
    
    def push_data(self, data: Union[Dict[str, Any], List[Dict[str, Any]], pd.DataFrame]) -> bool:
        """ë°ì´í„° ì…ë ¥"""
        if not self.is_running:
            self.logger.warning("Stream is not running")
            return False
        
        try:
            # ë°±í”„ë ˆì…” í™•ì¸
            if self.config.enable_backpressure and self.input_buffer.qsize() > self.config.buffer_size * 0.9:
                if not self.backpressure_active:
                    self.logger.warning("Backpressure activated")
                    self.backpressure_active = True
                return False
            
            self.backpressure_active = False
            
            # ë°ì´í„° ì •ê·œí™”
            normalized_data = self._normalize_input_data(data)
            
            # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
            for record in normalized_data:
                if 'timestamp' not in record:
                    record['timestamp'] = datetime.now()
            
            # ë²„í¼ì— ì¶”ê°€
            for record in normalized_data:
                try:
                    self.input_buffer.put_nowait(record)
                except queue.Full:
                    self.logger.warning("Input buffer is full, dropping data")
                    return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"Failed to push data: {e}")
            handle_error(
                e,
                ErrorCategory.DATA_PROCESSING,
                ErrorSeverity.MEDIUM,
                context={'data_type': type(data).__name__}
            )
            return False
    
    def _normalize_input_data(self, data: Union[Dict, List, pd.DataFrame]) -> List[Dict[str, Any]]:
        """ì…ë ¥ ë°ì´í„° ì •ê·œí™”"""
        if isinstance(data, dict):
            return [data]
        elif isinstance(data, list):
            return data
        elif isinstance(data, pd.DataFrame):
            return data.to_dict('records')
        else:
            raise ValueError(f"Unsupported data type: {type(data)}")
    
    def _processing_loop(self):
        """ë©”ì¸ ì²˜ë¦¬ ë£¨í”„"""
        batch = []
        last_batch_time = time.time()
        
        while self.is_running:
            try:
                if self.is_paused:
                    time.sleep(0.1)
                    continue
                
                current_time = time.time()
                
                # ë°ì´í„° ìˆ˜ì§‘
                try:
                    # íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    timeout = max(0.001, (self.config.max_latency_ms - (current_time - last_batch_time) * 1000) / 1000)
                    record = self.input_buffer.get(timeout=timeout)
                    batch.append(record)
                    
                except queue.Empty:
                    # íƒ€ì„ì•„ì›ƒ ë°œìƒì‹œ í˜„ì¬ ë°°ì¹˜ ì²˜ë¦¬
                    pass
                
                # ë°°ì¹˜ ì²˜ë¦¬ ì¡°ê±´ í™•ì¸
                should_process = (
                    len(batch) >= self.config.batch_size or
                    (batch and (current_time - last_batch_time) * 1000 > self.config.max_latency_ms)
                )
                
                if should_process and batch:
                    self._process_batch(batch)
                    batch = []
                    last_batch_time = current_time
                
                # ì²´í¬í¬ì¸íŠ¸
                if (datetime.now() - self.last_checkpoint).seconds > self.config.checkpoint_interval:
                    self._create_checkpoint()
                    self.last_checkpoint = datetime.now()
                
            except Exception as e:
                self.logger.error(f"Processing loop error: {e}")
                handle_error(
                    e,
                    ErrorCategory.DATA_PROCESSING,
                    ErrorSeverity.MEDIUM,
                    context={'batch_size': len(batch)}
                )
                time.sleep(0.1)
        
        # ì¢…ë£Œì‹œ ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
        if batch:
            self._process_batch(batch)
    
    def _process_batch(self, batch: List[Dict[str, Any]]):
        """ë°°ì¹˜ ì²˜ë¦¬"""
        start_time = time.time()
        
        try:
            # DataFrameìœ¼ë¡œ ë³€í™˜
            df = pd.DataFrame(batch)
            
            # ìœˆë„ìš° ì²˜ë¦¬
            if self.config.mode == StreamingMode.WINDOWED:
                self._process_windowed_batch(df)
            else:
                # ì§ì ‘ ì²˜ë¦¬
                results = self._apply_processors(df)
                
                # ì¶œë ¥ ë²„í¼ì— ì¶”ê°€
                if results is not None:
                    self.output_buffer.put({
                        'timestamp': datetime.now(),
                        'batch_size': len(batch),
                        'results': results
                    })
            
            # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            processing_time = (time.time() - start_time) * 1000
            self.metrics.processed_records += len(batch)
            self._update_processing_metrics(processing_time, len(batch))
            
        except Exception as e:
            self.logger.error(f"Batch processing failed: {e}")
            self.metrics.failed_records += len(batch)
            raise
    
    def _process_windowed_batch(self, df: pd.DataFrame):
        """ìœˆë„ìš° ê¸°ë°˜ ë°°ì¹˜ ì²˜ë¦¬"""
        if self.config.window_type == WindowType.TUMBLING:
            self._process_tumbling_window(df)
        elif self.config.window_type == WindowType.SLIDING:
            self._process_sliding_window(df)
        elif self.config.window_type == WindowType.COUNT:
            self._process_count_window(df)
        else:
            self.logger.warning(f"Unsupported window type: {self.config.window_type}")
    
    def _process_tumbling_window(self, df: pd.DataFrame):
        """í…€ë¸”ë§ ìœˆë„ìš° ì²˜ë¦¬"""
        for _, record in df.iterrows():
            record_dict = record.to_dict()
            
            # í˜„ì¬ í™œì„± ìœˆë„ìš° ì°¾ê¸°
            current_window = None
            for window in self.windows.values():
                if not window.is_complete:
                    current_window = window
                    break
            
            # ìƒˆ ìœˆë„ìš° ìƒì„±
            if current_window is None:
                self.window_counter += 1
                current_window = StreamWindow(
                    window_id=f"window_{self.window_counter}",
                    window_type=self.config.window_type,
                    size=self.config.window_size,
                    start_time=datetime.now()
                )
                self.windows[current_window.window_id] = current_window
            
            # ìœˆë„ìš°ì— ë°ì´í„° ì¶”ê°€
            current_window.data.append(record_dict)
            
            # ìœˆë„ìš° ì™„ë£Œ í™•ì¸
            if self._is_window_complete(current_window):
                current_window.is_complete = True
                current_window.end_time = datetime.now()
                
                # ìœˆë„ìš° ì²˜ë¦¬
                self._process_completed_window(current_window)
    
    def _process_sliding_window(self, df: pd.DataFrame):
        """ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì²˜ë¦¬"""
        # êµ¬í˜„: ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ëŠ” ê²¹ì¹˜ëŠ” ìœˆë„ìš°ë“¤ì„ ê´€ë¦¬
        pass
    
    def _process_count_window(self, df: pd.DataFrame):
        """ì¹´ìš´íŠ¸ ê¸°ë°˜ ìœˆë„ìš° ì²˜ë¦¬"""
        # êµ¬í˜„: ê³ ì • ê°œìˆ˜ ê¸°ë°˜ ìœˆë„ìš°
        pass
    
    def _is_window_complete(self, window: StreamWindow) -> bool:
        """ìœˆë„ìš° ì™„ë£Œ ì—¬ë¶€ í™•ì¸"""
        if isinstance(self.config.window_size, int):
            return len(window.data) >= self.config.window_size
        elif isinstance(self.config.window_size, timedelta):
            if window.start_time:
                return datetime.now() - window.start_time >= self.config.window_size
        return False
    
    def _process_completed_window(self, window: StreamWindow):
        """ì™„ë£Œëœ ìœˆë„ìš° ì²˜ë¦¬"""
        try:
            # ìœˆë„ìš° ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
            window_df = pd.DataFrame(list(window.data))
            
            # ì²˜ë¦¬ í•¨ìˆ˜ ì ìš©
            results = self._apply_processors(window_df)
            
            # ê²°ê³¼ ì¶œë ¥
            if results is not None:
                self.output_buffer.put({
                    'window_id': window.window_id,
                    'window_type': window.window_type.value,
                    'start_time': window.start_time,
                    'end_time': window.end_time,
                    'record_count': len(window.data),
                    'results': results
                })
            
            # ì™„ë£Œëœ ìœˆë„ìš° ì •ë¦¬
            del self.windows[window.window_id]
            
        except Exception as e:
            self.logger.error(f"Window processing failed: {e}")
    
    def _apply_processors(self, df: pd.DataFrame) -> Optional[Any]:
        """ì²˜ë¦¬ í•¨ìˆ˜ë“¤ ì ìš©"""
        try:
            result = df
            
            for processor in self.processors:
                result = processor(result)
                if result is None:
                    break
            
            return result
            
        except Exception as e:
            self.logger.error(f"Processor application failed: {e}")
            return None
    
    def _output_loop(self):
        """ì¶œë ¥ ì²˜ë¦¬ ë£¨í”„"""
        while self.is_running:
            try:
                # ì¶œë ¥ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                try:
                    output_data = self.output_buffer.get(timeout=1.0)
                    
                    # ì¶œë ¥ í•¸ë“¤ëŸ¬ë“¤ ì‹¤í–‰
                    for handler in self.output_handlers:
                        try:
                            handler(output_data)
                        except Exception as e:
                            self.logger.error(f"Output handler failed: {e}")
                    
                    # ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ ì „ì†¡
                    realtime_manager.send_update(
                        update_type=UpdateType.DATA_PROCESSING,
                        data={
                            'type': 'streaming_result',
                            'timestamp': output_data.get('timestamp', datetime.now()).isoformat(),
                            'record_count': output_data.get('record_count', 0)
                        }
                    )
                    
                except queue.Empty:
                    continue
                    
            except Exception as e:
                self.logger.error(f"Output loop error: {e}")
                time.sleep(0.1)
    
    def _metrics_loop(self):
        """ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ë£¨í”„"""
        while self.is_running:
            try:
                self._update_system_metrics()
                
                # ë©”íŠ¸ë¦­ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ì†¡
                realtime_manager.send_update(
                    update_type=UpdateType.METRIC_UPDATE,
                    data={
                        'type': 'streaming_metrics',
                        'metrics': {
                            'processed_records': self.metrics.processed_records,
                            'throughput_per_second': self.metrics.throughput_per_second,
                            'current_latency_ms': self.metrics.current_latency_ms,
                            'buffer_utilization': self.metrics.buffer_utilization,
                            'memory_usage_mb': self.metrics.memory_usage_mb
                        },
                        'timestamp': datetime.now().isoformat()
                    }
                )
                
                time.sleep(1)  # 1ì´ˆë§ˆë‹¤ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                
            except Exception as e:
                self.logger.error(f"Metrics loop error: {e}")
    
    def _update_processing_metrics(self, processing_time_ms: float, batch_size: int):
        """ì²˜ë¦¬ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸ (ì§€ìˆ˜ ì´ë™ í‰ê· )
        alpha = 0.1
        self.metrics.avg_processing_time_ms = (
            alpha * processing_time_ms + (1 - alpha) * self.metrics.avg_processing_time_ms
        )
        
        # ì²˜ë¦¬ëŸ‰ ê³„ì‚° (ì§€ìˆ˜ ì´ë™ í‰ê· )
        current_throughput = batch_size / (processing_time_ms / 1000) if processing_time_ms > 0 else 0
        self.metrics.throughput_per_second = (
            alpha * current_throughput + (1 - alpha) * self.metrics.throughput_per_second
        )
        
        # ì§€ì—°ì‹œê°„ ì—…ë°ì´íŠ¸
        self.metrics.current_latency_ms = processing_time_ms
        
        self.metrics.last_update = datetime.now()
    
    def _update_system_metrics(self):
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        try:
            # ë²„í¼ ì‚¬ìš©ë¥ 
            self.metrics.buffer_utilization = self.input_buffer.qsize() / self.config.buffer_size
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ì¶”ì •)
            import psutil
            process = psutil.Process()
            self.metrics.memory_usage_mb = process.memory_info().rss / 1024 / 1024
            
        except Exception as e:
            self.logger.debug(f"System metrics update failed: {e}")
    
    def _create_checkpoint(self):
        """ì²´í¬í¬ì¸íŠ¸ ìƒì„±"""
        try:
            checkpoint_data = {
                'timestamp': datetime.now().isoformat(),
                'metrics': {
                    'processed_records': self.metrics.processed_records,
                    'failed_records': self.metrics.failed_records,
                    'avg_processing_time_ms': self.metrics.avg_processing_time_ms,
                    'throughput_per_second': self.metrics.throughput_per_second
                },
                'active_windows': len([w for w in self.windows.values() if not w.is_complete]),
                'buffer_size': self.input_buffer.qsize()
            }
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” íŒŒì¼ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥)
            self.logger.debug(f"Checkpoint created: {json.dumps(checkpoint_data, indent=2)}")
            
        except Exception as e:
            self.logger.error(f"Checkpoint creation failed: {e}")
    
    def _flush_remaining_data(self):
        """ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬"""
        try:
            # ì…ë ¥ ë²„í¼ì˜ ë‚¨ì€ ë°ì´í„° ì²˜ë¦¬
            remaining_batch = []
            while not self.input_buffer.empty():
                try:
                    record = self.input_buffer.get_nowait()
                    remaining_batch.append(record)
                except queue.Empty:
                    break
            
            if remaining_batch:
                self.logger.info(f"Processing {len(remaining_batch)} remaining records")
                self._process_batch(remaining_batch)
            
            # ë¯¸ì™„ë£Œ ìœˆë„ìš° ì²˜ë¦¬
            for window in list(self.windows.values()):
                if not window.is_complete and window.data:
                    self.logger.info(f"Processing incomplete window: {window.window_id}")
                    window.is_complete = True
                    window.end_time = datetime.now()
                    self._process_completed_window(window)
            
        except Exception as e:
            self.logger.error(f"Failed to flush remaining data: {e}")
    
    def get_metrics(self) -> Dict[str, Any]:
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        return {
            'processed_records': self.metrics.processed_records,
            'failed_records': self.metrics.failed_records,
            'avg_processing_time_ms': self.metrics.avg_processing_time_ms,
            'throughput_per_second': self.metrics.throughput_per_second,
            'current_latency_ms': self.metrics.current_latency_ms,
            'buffer_utilization': self.metrics.buffer_utilization,
            'memory_usage_mb': self.metrics.memory_usage_mb,
            'active_windows': len([w for w in self.windows.values() if not w.is_complete]),
            'backpressure_active': self.backpressure_active,
            'is_running': self.is_running,
            'is_paused': self.is_paused,
            'last_update': self.metrics.last_update.isoformat()
        }


# íŠ¹í™”ëœ ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œì„¸ì„œë“¤
class FactorStreamProcessor:
    """íŒ©í„° ê³„ì‚° ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œì„¸ì„œ"""
    
    def __init__(self):
        self.logger = get_logger("factor_stream_processor")
        self.price_history = deque(maxlen=100)  # ìµœê·¼ 100ê°œ ê°€ê²©
    
    def __call__(self, df: pd.DataFrame) -> pd.DataFrame:
        """íŒ©í„° ê³„ì‚°"""
        try:
            result = df.copy()
            
            # ê°€ê²© íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸
            if 'close' in df.columns:
                for price in df['close']:
                    self.price_history.append(price)
            
            # ì‹¤ì‹œê°„ íŒ©í„° ê³„ì‚°
            if len(self.price_history) >= 5:
                prices = list(self.price_history)
                
                # ëª¨ë©˜í…€ íŒ©í„°
                if 'close' in result.columns:
                    result['momentum_5'] = result['close'].pct_change(min(5, len(prices)))
                    result['rsi'] = self._calculate_rsi(prices[-14:] if len(prices) >= 14 else prices)
            
            return result
            
        except Exception as e:
            self.logger.error(f"Factor calculation failed: {e}")
            return df
    
    def _calculate_rsi(self, prices: List[float], period: int = 14) -> float:
        """RSI ê³„ì‚°"""
        if len(prices) < 2:
            return 50.0
        
        deltas = [prices[i] - prices[i-1] for i in range(1, len(prices))]
        gains = [d if d > 0 else 0 for d in deltas]
        losses = [-d if d < 0 else 0 for d in deltas]
        
        if len(gains) == 0 or len(losses) == 0:
            return 50.0
        
        avg_gain = sum(gains) / len(gains)
        avg_loss = sum(losses) / len(losses)
        
        if avg_loss == 0:
            return 100.0
        
        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))
        
        return rsi


class AlertStreamProcessor:
    """ì•Œë¦¼ ìŠ¤íŠ¸ë¦¬ë° í”„ë¡œì„¸ì„œ"""
    
    def __init__(self, thresholds: Dict[str, float]):
        self.thresholds = thresholds
        self.logger = get_logger("alert_stream_processor")
    
    def __call__(self, df: pd.DataFrame) -> Optional[Dict[str, Any]]:
        """ì•Œë¦¼ ì¡°ê±´ í™•ì¸"""
        alerts = []
        
        try:
            for _, row in df.iterrows():
                for column, threshold in self.thresholds.items():
                    if column in row and abs(row[column]) > threshold:
                        alerts.append({
                            'timestamp': row.get('timestamp', datetime.now()).isoformat(),
                            'column': column,
                            'value': row[column],
                            'threshold': threshold,
                            'severity': 'high' if abs(row[column]) > threshold * 1.5 else 'medium'
                        })
            
            return {'alerts': alerts} if alerts else None
            
        except Exception as e:
            self.logger.error(f"Alert processing failed: {e}")
            return None


# Streamlit í†µí•©
def show_streaming_dashboard(processor: StreamingProcessor):
    """ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹œë³´ë“œ í‘œì‹œ"""
    import streamlit as st
    
    st.subheader("ğŸŒŠ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ëŒ€ì‹œë³´ë“œ")
    
    # ìƒíƒœ í‘œì‹œ
    metrics = processor.get_metrics()
    
    # ìƒíƒœ ì¸ë””ì¼€ì´í„°
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        status = "ì‹¤í–‰ ì¤‘" if metrics['is_running'] else "ì¤‘ì§€"
        if metrics['is_paused']:
            status += " (ì¼ì‹œì •ì§€)"
        st.metric("ìƒíƒœ", status)
    
    with col2:
        st.metric("ì²˜ë¦¬ëœ ë ˆì½”ë“œ", metrics['processed_records'])
    
    with col3:
        st.metric("ì²˜ë¦¬ëŸ‰ (/ì´ˆ)", f"{metrics['throughput_per_second']:.1f}")
    
    with col4:
        st.metric("í‰ê·  ì§€ì—°ì‹œê°„ (ms)", f"{metrics['avg_processing_time_ms']:.1f}")
    
    # ë²„í¼ ì‚¬ìš©ë¥ 
    st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("ë²„í¼ ì‚¬ìš©ë¥ ", f"{metrics['buffer_utilization']*100:.1f}%")
        st.progress(metrics['buffer_utilization'])
    
    with col2:
        st.metric("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰", f"{metrics['memory_usage_mb']:.1f} MB")
    
    # ë°±í”„ë ˆì…” ìƒíƒœ
    if metrics['backpressure_active']:
        st.error("âš ï¸ ë°±í”„ë ˆì…” í™œì„±í™”: ì…ë ¥ ì†ë„ë¥¼ ì¤„ì´ì„¸ìš”")
    
    # ì œì–´ ë²„íŠ¼
    st.subheader("ğŸ›ï¸ ì œì–´")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ì¼ì‹œì •ì§€" if metrics['is_running'] and not metrics['is_paused'] else "ì¬ê°œ"):
            if metrics['is_running'] and not metrics['is_paused']:
                processor.pause_stream()
            else:
                processor.resume_stream()
            st.experimental_rerun()
    
    with col2:
        if st.button("ì¤‘ì§€"):
            processor.stop_stream()
            st.experimental_rerun()
    
    with col3:
        if st.button("ë©”íŠ¸ë¦­ ìƒˆë¡œê³ ì¹¨"):
            st.experimental_rerun()


def create_streaming_config_ui() -> StreamingConfig:
    """ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • UI ìƒì„±"""
    import streamlit as st
    
    st.subheader("âš™ï¸ ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •")
    
    col1, col2 = st.columns(2)
    
    with col1:
        mode = st.selectbox(
            "ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ",
            options=[m.value for m in StreamingMode],
            index=0
        )
        
        buffer_size = st.number_input("ë²„í¼ í¬ê¸°", min_value=100, max_value=10000, value=1000)
        
        batch_size = st.number_input("ë°°ì¹˜ í¬ê¸°", min_value=1, max_value=1000, value=100)
        
        max_latency_ms = st.number_input("ìµœëŒ€ ì§€ì—°ì‹œê°„ (ms)", min_value=10, max_value=10000, value=1000)
    
    with col2:
        window_type = st.selectbox(
            "ìœˆë„ìš° íƒ€ì…",
            options=[w.value for w in WindowType],
            index=0
        )
        
        window_size = st.number_input("ìœˆë„ìš° í¬ê¸°", min_value=10, max_value=10000, value=100)
        
        checkpoint_interval = st.number_input("ì²´í¬í¬ì¸íŠ¸ ê°„ê²© (ì´ˆ)", min_value=10, max_value=3600, value=60)
        
        enable_backpressure = st.checkbox("ë°±í”„ë ˆì…” í™œì„±í™”", value=True)
    
    return StreamingConfig(
        mode=StreamingMode(mode),
        buffer_size=buffer_size,
        batch_size=batch_size,
        window_size=window_size,
        window_type=WindowType(window_type),
        slide_interval=None,
        max_latency_ms=max_latency_ms,
        checkpoint_interval=checkpoint_interval,
        enable_backpressure=enable_backpressure,
        max_memory_mb=1000
    )


# ì˜ˆì œ ì‚¬ìš©ë²•
def create_example_streaming_pipeline():
    """ì˜ˆì œ ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ ìƒì„±"""
    # ì„¤ì • ìƒì„±
    config = StreamingConfig(
        mode=StreamingMode.MICRO_BATCH,
        buffer_size=1000,
        batch_size=50,
        window_size=100,
        window_type=WindowType.TUMBLING,
        max_latency_ms=500,
        checkpoint_interval=30,
        enable_backpressure=True,
        max_memory_mb=500
    )
    
    # í”„ë¡œì„¸ì„œ ìƒì„±
    processor = StreamingProcessor(config)
    
    # ì²˜ë¦¬ í•¨ìˆ˜ ì¶”ê°€
    factor_processor = FactorStreamProcessor()
    processor.add_processor(factor_processor)
    
    # ì•Œë¦¼ í”„ë¡œì„¸ì„œ ì¶”ê°€
    alert_processor = AlertStreamProcessor({'momentum_5': 0.05, 'rsi': 80})
    processor.add_processor(alert_processor)
    
    # ì¶œë ¥ í•¸ë“¤ëŸ¬ ì¶”ê°€
    def print_output(data):
        print(f"Processed at {data.get('timestamp')}: {data.get('record_count')} records")
    
    processor.add_output_handler(print_output)
    
    return processor