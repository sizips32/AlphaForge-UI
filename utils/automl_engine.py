"""
AutoML ì—”ì§„ ë° ìë™ ëª¨ë¸ ì„ íƒ ì‹œìŠ¤í…œ
ìë™í™”ëœ ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ê³¼ ëª¨ë¸ ìµœì í™”
"""

import streamlit as st
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Union, Tuple, Callable
from datetime import datetime, timedelta
import json
import pickle
from dataclasses import dataclass, asdict
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV
    from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler
    from sklearn.preprocessing import LabelEncoder, OneHotEncoder
    from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
    from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier
    from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso
    from sklearn.svm import SVR, SVC
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
    from sklearn.metrics import classification_report, confusion_matrix
    from sklearn.pipeline import Pipeline
    from sklearn.compose import ColumnTransformer
    from sklearn.impute import SimpleImputer
    from sklearn.feature_selection import SelectKBest, f_regression, f_classif
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    st.warning("Scikit-learnì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AutoML ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")

try:
    from xgboost import XGBRegressor, XGBClassifier
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    from lightgbm import LGBMRegressor, LGBMClassifier
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

class ProblemType(Enum):
    REGRESSION = "regression"
    BINARY_CLASSIFICATION = "binary_classification"
    MULTICLASS_CLASSIFICATION = "multiclass_classification"
    TIME_SERIES = "time_series"

class ModelType(Enum):
    LINEAR = "linear"
    TREE_BASED = "tree_based"
    ENSEMBLE = "ensemble"
    BOOSTING = "boosting"
    NEURAL_NETWORK = "neural_network"

@dataclass
class ModelResult:
    model_name: str
    model_type: ModelType
    score: float
    cv_score: float
    cv_std: float
    training_time: float
    parameters: Dict[str, Any]
    feature_importance: Optional[Dict[str, float]] = None
    model_object: Optional[Any] = None
    preprocessing_pipeline: Optional[Any] = None

@dataclass
class AutoMLConfig:
    problem_type: ProblemType
    target_column: str
    feature_columns: List[str]
    test_size: float = 0.2
    cv_folds: int = 5
    random_state: int = 42
    max_time_minutes: int = 30
    n_jobs: int = -1
    scoring_metric: Optional[str] = None
    optimize_for: str = "accuracy"  # accuracy, speed, interpretability

class AutoMLEngine:
    """ìë™ ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§„"""
    
    def __init__(self, config: AutoMLConfig):
        self.config = config
        self.results: List[ModelResult] = []
        self.best_model: Optional[ModelResult] = None
        self.preprocessor = None
        self.is_trained = False
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ ì´ˆê¸°í™”
        self.available_models = self._initialize_models()
    
    def _initialize_models(self) -> Dict[str, Dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        models = {}
        
        if not SKLEARN_AVAILABLE:
            return models
        
        if self.config.problem_type == ProblemType.REGRESSION:
            models.update({
                'linear_regression': {
                    'model': LinearRegression,
                    'params': {},
                    'type': ModelType.LINEAR
                },
                'ridge_regression': {
                    'model': Ridge,
                    'params': {'alpha': [0.1, 1.0, 10.0, 100.0]},
                    'type': ModelType.LINEAR
                },
                'lasso_regression': {
                    'model': Lasso,
                    'params': {'alpha': [0.01, 0.1, 1.0, 10.0]},
                    'type': ModelType.LINEAR
                },
                'random_forest': {
                    'model': RandomForestRegressor,
                    'params': {
                        'n_estimators': [50, 100, 200],
                        'max_depth': [5, 10, 20, None],
                        'min_samples_split': [2, 5, 10],
                        'min_samples_leaf': [1, 2, 4]
                    },
                    'type': ModelType.ENSEMBLE
                },
                'gradient_boosting': {
                    'model': GradientBoostingRegressor,
                    'params': {
                        'n_estimators': [50, 100, 200],
                        'learning_rate': [0.01, 0.1, 0.2],
                        'max_depth': [3, 5, 7]
                    },
                    'type': ModelType.BOOSTING
                }
            })
            
            # XGBoost ì¶”ê°€
            if XGBOOST_AVAILABLE:
                models['xgboost'] = {
                    'model': XGBRegressor,
                    'params': {
                        'n_estimators': [50, 100, 200],
                        'learning_rate': [0.01, 0.1, 0.2],
                        'max_depth': [3, 5, 7],
                        'subsample': [0.8, 0.9, 1.0]
                    },
                    'type': ModelType.BOOSTING
                }
            
            # LightGBM ì¶”ê°€
            if LIGHTGBM_AVAILABLE:
                models['lightgbm'] = {
                    'model': LGBMRegressor,
                    'params': {
                        'n_estimators': [50, 100, 200],
                        'learning_rate': [0.01, 0.1, 0.2],
                        'max_depth': [3, 5, 7],
                        'num_leaves': [31, 50, 100]
                    },
                    'type': ModelType.BOOSTING
                }
        
        else:  # Classification
            models.update({
                'logistic_regression': {
                    'model': LogisticRegression,
                    'params': {
                        'C': [0.1, 1.0, 10.0, 100.0],
                        'solver': ['liblinear', 'lbfgs']
                    },
                    'type': ModelType.LINEAR
                },
                'random_forest': {
                    'model': RandomForestClassifier,
                    'params': {
                        'n_estimators': [50, 100, 200],
                        'max_depth': [5, 10, 20, None],
                        'min_samples_split': [2, 5, 10],
                        'min_samples_leaf': [1, 2, 4]
                    },
                    'type': ModelType.ENSEMBLE
                },
                'gradient_boosting': {
                    'model': GradientBoostingClassifier,
                    'params': {
                        'n_estimators': [50, 100, 200],
                        'learning_rate': [0.01, 0.1, 0.2],
                        'max_depth': [3, 5, 7]
                    },
                    'type': ModelType.BOOSTING
                }
            })
            
            # XGBoost ë¶„ë¥˜
            if XGBOOST_AVAILABLE:
                models['xgboost'] = {
                    'model': XGBClassifier,
                    'params': {
                        'n_estimators': [50, 100, 200],
                        'learning_rate': [0.01, 0.1, 0.2],
                        'max_depth': [3, 5, 7],
                        'subsample': [0.8, 0.9, 1.0]
                    },
                    'type': ModelType.BOOSTING
                }
            
            # LightGBM ë¶„ë¥˜
            if LIGHTGBM_AVAILABLE:
                models['lightgbm'] = {
                    'model': LGBMClassifier,
                    'params': {
                        'n_estimators': [50, 100, 200],
                        'learning_rate': [0.01, 0.1, 0.2],
                        'max_depth': [3, 5, 7],
                        'num_leaves': [31, 50, 100]
                    },
                    'type': ModelType.BOOSTING
                }
        
        return models
    
    def detect_problem_type(self, data: pd.DataFrame, target_column: str) -> ProblemType:
        """ë¬¸ì œ ìœ í˜• ìë™ ê°ì§€"""
        target_series = data[target_column]
        
        # ìˆ˜ì¹˜í˜• ë°ì´í„°ì¸ì§€ í™•ì¸
        if pd.api.types.is_numeric_dtype(target_series):
            unique_values = target_series.nunique()
            total_values = len(target_series)
            
            # ê³ ìœ ê°’ì˜ ë¹„ìœ¨ì´ ë‚®ìœ¼ë©´ ë¶„ë¥˜, ë†’ìœ¼ë©´ íšŒê·€
            unique_ratio = unique_values / total_values
            
            if unique_ratio < 0.05 or unique_values <= 10:
                if unique_values == 2:
                    return ProblemType.BINARY_CLASSIFICATION
                else:
                    return ProblemType.MULTICLASS_CLASSIFICATION
            else:
                return ProblemType.REGRESSION
        else:
            # ë¬¸ìì—´ì´ë‚˜ ì¹´í…Œê³ ë¦¬ ë°ì´í„°
            unique_values = target_series.nunique()
            if unique_values == 2:
                return ProblemType.BINARY_CLASSIFICATION
            else:
                return ProblemType.MULTICLASS_CLASSIFICATION
    
    def create_preprocessing_pipeline(self, data: pd.DataFrame) -> ColumnTransformer:
        """ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        numeric_features = data.select_dtypes(include=[np.number]).columns.tolist()
        categorical_features = data.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # íƒ€ê²Ÿ ì»¬ëŸ¼ ì œê±°
        if self.config.target_column in numeric_features:
            numeric_features.remove(self.config.target_column)
        if self.config.target_column in categorical_features:
            categorical_features.remove(self.config.target_column)
        
        transformers = []
        
        # ìˆ˜ì¹˜í˜• ë°ì´í„° ì „ì²˜ë¦¬
        if numeric_features:
            numeric_pipeline = Pipeline([
                ('imputer', SimpleImputer(strategy='median')),
                ('scaler', StandardScaler())
            ])
            transformers.append(('num', numeric_pipeline, numeric_features))
        
        # ì¹´í…Œê³ ë¦¬í˜• ë°ì´í„° ì „ì²˜ë¦¬
        if categorical_features:
            categorical_pipeline = Pipeline([
                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
            ])
            transformers.append(('cat', categorical_pipeline, categorical_features))
        
        return ColumnTransformer(transformers=transformers, remainder='drop')
    
    def train_model(self, data: pd.DataFrame) -> List[ModelResult]:
        """ëª¨ë¸ í›ˆë ¨"""
        if not SKLEARN_AVAILABLE:
            st.error("Scikit-learnì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return []
        
        st.info("AutoML í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        
        # ë°ì´í„° ì¤€ë¹„
        X = data[self.config.feature_columns]
        y = data[self.config.target_column]
        
        # ë¼ë²¨ ì¸ì½”ë”© (ë¶„ë¥˜ ë¬¸ì œì˜ ê²½ìš°)
        label_encoder = None
        if self.config.problem_type in [ProblemType.BINARY_CLASSIFICATION, ProblemType.MULTICLASS_CLASSIFICATION]:
            label_encoder = LabelEncoder()
            y = label_encoder.fit_transform(y)
        
        # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„±
        self.preprocessor = self.create_preprocessing_pipeline(X)
        
        # ë°ì´í„° ë¶„í• 
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=self.config.test_size, random_state=self.config.random_state
        )
        
        # ì „ì²˜ë¦¬ ì ìš©
        X_train_processed = self.preprocessor.fit_transform(X_train)
        X_test_processed = self.preprocessor.transform(X_test)
        
        # ìŠ¤ì½”ì–´ë§ ë©”íŠ¸ë¦­ ì„¤ì •
        if self.config.scoring_metric is None:
            if self.config.problem_type == ProblemType.REGRESSION:
                scoring = 'r2'
            else:
                scoring = 'accuracy'
        else:
            scoring = self.config.scoring_metric
        
        results = []
        
        # ê° ëª¨ë¸ í›ˆë ¨
        progress_bar = st.progress(0)
        total_models = len(self.available_models)
        
        for i, (model_name, model_config) in enumerate(self.available_models.items()):
            try:
                start_time = datetime.now()
                
                st.write(f"í›ˆë ¨ ì¤‘: {model_name}")
                
                # ëª¨ë¸ ìƒì„±
                model = model_config['model']()
                
                # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
                if model_config['params']:
                    # ê°„ë‹¨í•œ ëœë¤ ì„œì¹˜ ì‚¬ìš© (ì‹œê°„ ì œí•œì„ ìœ„í•´)
                    search = RandomizedSearchCV(
                        model, 
                        model_config['params'],
                        n_iter=10,  # ì œí•œëœ ë°˜ë³µ
                        cv=min(self.config.cv_folds, 3),  # ë” ì ì€ í´ë“œ
                        scoring=scoring,
                        random_state=self.config.random_state,
                        n_jobs=1  # ì•ˆì •ì„±ì„ ìœ„í•´ 1ë¡œ ì„¤ì •
                    )
                    search.fit(X_train_processed, y_train)
                    best_model = search.best_estimator_
                    best_params = search.best_params_
                else:
                    best_model = model
                    best_params = {}
                    best_model.fit(X_train_processed, y_train)
                
                # êµì°¨ ê²€ì¦ ì ìˆ˜
                cv_scores = cross_val_score(
                    best_model, X_train_processed, y_train, 
                    cv=min(self.config.cv_folds, 3), scoring=scoring
                )
                
                # í…ŒìŠ¤íŠ¸ ì ìˆ˜
                test_score = best_model.score(X_test_processed, y_test)
                
                # íŠ¹ì„± ì¤‘ìš”ë„ (ê°€ëŠ¥í•œ ê²½ìš°)
                feature_importance = None
                if hasattr(best_model, 'feature_importances_'):
                    # íŠ¹ì„± ì´ë¦„ ìƒì„±
                    feature_names = self.preprocessor.get_feature_names_out()
                    importance_dict = dict(zip(feature_names, best_model.feature_importances_))
                    # ìƒìœ„ 10ê°œë§Œ ì €ì¥
                    sorted_importance = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)
                    feature_importance = dict(sorted_importance[:10])
                
                # í›ˆë ¨ ì‹œê°„ ê³„ì‚°
                training_time = (datetime.now() - start_time).total_seconds()
                
                # ê²°ê³¼ ì €ì¥
                result = ModelResult(
                    model_name=model_name,
                    model_type=model_config['type'],
                    score=test_score,
                    cv_score=cv_scores.mean(),
                    cv_std=cv_scores.std(),
                    training_time=training_time,
                    parameters=best_params,
                    feature_importance=feature_importance,
                    model_object=best_model
                )
                
                results.append(result)
                
                st.success(f"âœ… {model_name}: {test_score:.4f}")
                
            except Exception as e:
                st.warning(f"âš ï¸ {model_name} í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress_bar.progress((i + 1) / total_models)
        
        # ê²°ê³¼ ì •ë ¬ (ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
        results.sort(key=lambda x: x.score, reverse=True)
        
        self.results = results
        if results:
            self.best_model = results[0]
            self.is_trained = True
        
        return results
    
    def get_model_comparison(self) -> pd.DataFrame:
        """ëª¨ë¸ ë¹„êµ í…Œì´ë¸” ìƒì„±"""
        if not self.results:
            return pd.DataFrame()
        
        comparison_data = []
        for result in self.results:
            comparison_data.append({
                'Model': result.model_name.replace('_', ' ').title(),
                'Type': result.model_type.value.replace('_', ' ').title(),
                'Test Score': f"{result.score:.4f}",
                'CV Score': f"{result.cv_score:.4f}",
                'CV Std': f"{result.cv_std:.4f}",
                'Training Time (s)': f"{result.training_time:.2f}",
                'Parameters': len(result.parameters)
            })
        
        return pd.DataFrame(comparison_data)
    
    def predict(self, data: pd.DataFrame) -> np.ndarray:
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        if not self.is_trained or not self.best_model:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì „ì²˜ë¦¬ ì ìš©
        X_processed = self.preprocessor.transform(data[self.config.feature_columns])
        
        # ì˜ˆì¸¡
        predictions = self.best_model.model_object.predict(X_processed)
        
        return predictions
    
    def save_model(self, filepath: str):
        """ëª¨ë¸ ì €ì¥"""
        if not self.is_trained:
            raise ValueError("í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        model_data = {
            'config': asdict(self.config),
            'best_model': self.best_model,
            'preprocessor': self.preprocessor,
            'results': self.results
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)
    
    def load_model(self, filepath: str):
        """ëª¨ë¸ ë¡œë“œ"""
        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)
        
        self.config = AutoMLConfig(**model_data['config'])
        self.best_model = model_data['best_model']
        self.preprocessor = model_data['preprocessor']
        self.results = model_data['results']
        self.is_trained = True

class ModelExplainer:
    """ëª¨ë¸ ì„¤ëª… ì‹œìŠ¤í…œ"""
    
    def __init__(self, automl_engine: AutoMLEngine):
        self.engine = automl_engine
    
    def explain_model(self, model_result: ModelResult) -> Dict[str, Any]:
        """ëª¨ë¸ ì„¤ëª… ìƒì„±"""
        explanation = {
            'model_name': model_result.model_name,
            'model_type': model_result.model_type.value,
            'performance_summary': self._create_performance_summary(model_result),
            'feature_importance': model_result.feature_importance,
            'model_characteristics': self._get_model_characteristics(model_result),
            'recommendations': self._get_recommendations(model_result)
        }
        
        return explanation
    
    def _create_performance_summary(self, model_result: ModelResult) -> str:
        """ì„±ëŠ¥ ìš”ì•½ ìƒì„±"""
        if self.engine.config.problem_type == ProblemType.REGRESSION:
            r2_percentage = model_result.score * 100
            summary = f"""
            ì´ ëª¨ë¸ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ {r2_percentage:.1f}%ì˜ ë³€ë™ì„±ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
            êµì°¨ ê²€ì¦ ì ìˆ˜ëŠ” {model_result.cv_score:.4f} (Â±{model_result.cv_std:.4f})ì…ë‹ˆë‹¤.
            """
        else:
            accuracy_percentage = model_result.score * 100
            summary = f"""
            ì´ ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ì •í™•ë„ëŠ” {accuracy_percentage:.1f}%ì…ë‹ˆë‹¤.
            êµì°¨ ê²€ì¦ ì •í™•ë„ëŠ” {model_result.cv_score:.4f} (Â±{model_result.cv_std:.4f})ì…ë‹ˆë‹¤.
            """
        
        return summary.strip()
    
    def _get_model_characteristics(self, model_result: ModelResult) -> Dict[str, str]:
        """ëª¨ë¸ íŠ¹ì„± ì„¤ëª…"""
        characteristics = {
            ModelType.LINEAR: {
                'interpretability': 'ë†’ìŒ',
                'training_speed': 'ë¹ ë¦„',
                'prediction_speed': 'ë§¤ìš° ë¹ ë¦„',
                'overfitting_risk': 'ë‚®ìŒ',
                'data_requirement': 'ì ìŒ'
            },
            ModelType.TREE_BASED: {
                'interpretability': 'ë†’ìŒ',
                'training_speed': 'ë¹ ë¦„',
                'prediction_speed': 'ë¹ ë¦„',
                'overfitting_risk': 'ë³´í†µ',
                'data_requirement': 'ë³´í†µ'
            },
            ModelType.ENSEMBLE: {
                'interpretability': 'ë³´í†µ',
                'training_speed': 'ë³´í†µ',
                'prediction_speed': 'ë³´í†µ',
                'overfitting_risk': 'ë‚®ìŒ',
                'data_requirement': 'ë³´í†µ'
            },
            ModelType.BOOSTING: {
                'interpretability': 'ë³´í†µ',
                'training_speed': 'ëŠë¦¼',
                'prediction_speed': 'ë¹ ë¦„',
                'overfitting_risk': 'ë³´í†µ',
                'data_requirement': 'ë§ìŒ'
            }
        }
        
        return characteristics.get(model_result.model_type, {})
    
    def _get_recommendations(self, model_result: ModelResult) -> List[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­"""
        recommendations = []
        
        # ì„±ëŠ¥ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if model_result.score < 0.7:
            recommendations.append("ëª¨ë¸ ì„±ëŠ¥ì´ ë‚®ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ë‚˜ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        # CV í‘œì¤€í¸ì°¨ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if model_result.cv_std > 0.1:
            recommendations.append("êµì°¨ ê²€ì¦ ì ìˆ˜ì˜ ë³€ë™ì„±ì´ í½ë‹ˆë‹¤. ëª¨ë¸ì˜ ì•ˆì •ì„±ì„ ê°œì„ í•´ë³´ì„¸ìš”.")
        
        # ëª¨ë¸ íƒ€ì…ë³„ ê¶Œì¥ì‚¬í•­
        if model_result.model_type == ModelType.LINEAR and model_result.score < 0.6:
            recommendations.append("ì„ í˜• ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë‚®ìŠµë‹ˆë‹¤. ë¹„ì„ í˜• ëª¨ë¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("ëª¨ë¸ ì„±ëŠ¥ì´ ì–‘í˜¸í•©ë‹ˆë‹¤. ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
        
        return recommendations

class AutoMLInterface:
    """AutoML ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.engine = None
        self.explainer = None
    
    def render_configuration(self) -> Optional[AutoMLConfig]:
        """ì„¤ì • ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
        st.markdown("### ğŸ¤– AutoML ì„¤ì •")
        
        # ë°ì´í„° ì—…ë¡œë“œ í™•ì¸
        if 'data' not in st.session_state or st.session_state.data is None:
            st.warning("ë¨¼ì € ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            return None
        
        data = st.session_state.data
        
        col1, col2 = st.columns(2)
        
        with col1:
            # íƒ€ê²Ÿ ì»¬ëŸ¼ ì„ íƒ
            target_column = st.selectbox(
                "íƒ€ê²Ÿ ì»¬ëŸ¼ ì„ íƒ",
                options=data.columns.tolist(),
                help="ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” ëª©í‘œ ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì„¸ìš”"
            )
            
            # ë¬¸ì œ ìœ í˜• ìë™ ê°ì§€
            if target_column:
                temp_engine = AutoMLEngine(AutoMLConfig(ProblemType.REGRESSION, target_column, []))
                detected_type = temp_engine.detect_problem_type(data, target_column)
                
                problem_type = st.selectbox(
                    "ë¬¸ì œ ìœ í˜•",
                    options=[e.value for e in ProblemType],
                    index=[e.value for e in ProblemType].index(detected_type.value),
                    format_func=lambda x: x.replace('_', ' ').title(),
                    help="ìë™ìœ¼ë¡œ ê°ì§€ëœ ë¬¸ì œ ìœ í˜•ì…ë‹ˆë‹¤"
                )
            
            # íŠ¹ì„± ì»¬ëŸ¼ ì„ íƒ
            available_features = [col for col in data.columns if col != target_column]
            feature_columns = st.multiselect(
                "íŠ¹ì„± ì»¬ëŸ¼ ì„ íƒ",
                options=available_features,
                default=available_features[:10],  # ì²˜ìŒ 10ê°œë§Œ ê¸°ë³¸ ì„ íƒ
                help="ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•  íŠ¹ì„±ë“¤ì„ ì„ íƒí•˜ì„¸ìš”"
            )
        
        with col2:
            # ê³ ê¸‰ ì„¤ì •
            st.markdown("#### ê³ ê¸‰ ì„¤ì •")
            
            test_size = st.slider(
                "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨",
                min_value=0.1, max_value=0.5, value=0.2, step=0.05,
                help="ì „ì²´ ë°ì´í„° ì¤‘ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì‚¬ìš©í•  ë¹„ìœ¨"
            )
            
            cv_folds = st.slider(
                "êµì°¨ ê²€ì¦ í´ë“œ ìˆ˜",
                min_value=3, max_value=10, value=5,
                help="êµì°¨ ê²€ì¦ì— ì‚¬ìš©í•  í´ë“œ ìˆ˜"
            )
            
            max_time = st.slider(
                "ìµœëŒ€ í›ˆë ¨ ì‹œê°„ (ë¶„)",
                min_value=5, max_value=60, value=30,
                help="AutoML í›ˆë ¨ì— ì‚¬ìš©í•  ìµœëŒ€ ì‹œê°„"
            )
            
            optimize_for = st.selectbox(
                "ìµœì í™” ëª©í‘œ",
                options=["accuracy", "speed", "interpretability"],
                help="ëª¨ë¸ ì„ íƒ ì‹œ ìš°ì„ ìˆœìœ„ë¥¼ ë‘˜ ê¸°ì¤€"
            )
        
        if not feature_columns:
            st.warning("ìµœì†Œ í•˜ë‚˜ì˜ íŠ¹ì„± ì»¬ëŸ¼ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
            return None
        
        # ì„¤ì • ìƒì„±
        config = AutoMLConfig(
            problem_type=ProblemType(problem_type),
            target_column=target_column,
            feature_columns=feature_columns,
            test_size=test_size,
            cv_folds=cv_folds,
            max_time_minutes=max_time,
            optimize_for=optimize_for
        )
        
        return config
    
    def render_training(self, config: AutoMLConfig):
        """í›ˆë ¨ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
        st.markdown("### ğŸš‚ ëª¨ë¸ í›ˆë ¨")
        
        if st.button("AutoML í›ˆë ¨ ì‹œì‘", type="primary"):
            self.engine = AutoMLEngine(config)
            
            with st.spinner("ëª¨ë¸ë“¤ì„ í›ˆë ¨í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                results = self.engine.train_model(st.session_state.data)
            
            if results:
                st.success(f"âœ… {len(results)}ê°œì˜ ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.session_state.automl_engine = self.engine
                st.session_state.automl_results = results
                
                # ìµœê³  ëª¨ë¸ ì •ë³´ í‘œì‹œ
                best_model = results[0]
                st.info(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model.model_name} (ì ìˆ˜: {best_model.score:.4f})")
            else:
                st.error("ëª¨ë¸ í›ˆë ¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    def render_results(self):
        """ê²°ê³¼ ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""
        if 'automl_engine' not in st.session_state or 'automl_results' not in st.session_state:
            st.info("ë¨¼ì € AutoML í›ˆë ¨ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")
            return
        
        engine = st.session_state.automl_engine
        results = st.session_state.automl_results
        
        st.markdown("### ğŸ“Š ëª¨ë¸ ë¹„êµ ê²°ê³¼")
        
        # ëª¨ë¸ ë¹„êµ í…Œì´ë¸”
        comparison_df = engine.get_model_comparison()
        st.dataframe(comparison_df, use_container_width=True)
        
        # ëª¨ë¸ ì„ íƒ
        selected_model_name = st.selectbox(
            "ìì„¸íˆ ë³¼ ëª¨ë¸ ì„ íƒ",
            options=[result.model_name for result in results],
            format_func=lambda x: x.replace('_', ' ').title()
        )
        
        # ì„ íƒëœ ëª¨ë¸ ìƒì„¸ ì •ë³´
        selected_result = next(r for r in results if r.model_name == selected_model_name)
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.markdown(f"#### {selected_result.model_name.replace('_', ' ').title()} ìƒì„¸ ì •ë³´")
            
            # ëª¨ë¸ ì„¤ëª…
            self.explainer = ModelExplainer(engine)
            explanation = self.explainer.explain_model(selected_result)
            
            st.write("**ì„±ëŠ¥ ìš”ì•½:**")
            st.write(explanation['performance_summary'])
            
            st.write("**ëª¨ë¸ íŠ¹ì„±:**")
            characteristics = explanation['model_characteristics']
            if characteristics:
                for key, value in characteristics.items():
                    st.write(f"- {key.replace('_', ' ').title()}: {value}")
            
            st.write("**ê¶Œì¥ì‚¬í•­:**")
            for recommendation in explanation['recommendations']:
                st.write(f"- {recommendation}")
        
        with col2:
            # íŠ¹ì„± ì¤‘ìš”ë„
            if selected_result.feature_importance:
                st.markdown("#### íŠ¹ì„± ì¤‘ìš”ë„")
                
                importance_df = pd.DataFrame(
                    list(selected_result.feature_importance.items()),
                    columns=['Feature', 'Importance']
                ).sort_values('Importance', ascending=False)
                
                import plotly.express as px
                fig = px.bar(
                    importance_df,
                    x='Importance',
                    y='Feature',
                    orientation='h',
                    title="Top 10 íŠ¹ì„± ì¤‘ìš”ë„"
                )
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
        
        # ëª¨ë¸ ì €ì¥
        st.markdown("#### ğŸ’¾ ëª¨ë¸ ì €ì¥")
        if st.button("ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥"):
            try:
                filename = f"automl_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl"
                engine.save_model(filename)
                st.success(f"ëª¨ë¸ì´ '{filename}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            except Exception as e:
                st.error(f"ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

# ì „ì—­ ì¸í„°í˜ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
automl_interface = AutoMLInterface()